

# Basic RAG App â€” Retrieval-Augmented Generation with Docker and Postgres

> **RAG = Retrieval-Augmented Generation**  
> RAG is an architecture that combines retrieval-based methods and generative models to enhance content accuracy and relevance. It leverages Docker for containerization, PostgreSQL for long-term data storage, LangChain for orchestration, ChromaDB for vector-based similarity search, LangGraph for graph-based data handling, and OpenAIâ€™s GPT for natural language generation.

Key components include:

**Docker** ensures a consistent and scalable environment for services. \n
**PostgreSQL** stores structured data like metadata or user information.
**ChromaDB** stores vector embeddings of data for fast semantic searches.
**LangChain** orchestrates the flow between databases, retrieval systems, and generative models.
**LangGraph** helps represent and retrieve connected data efficiently.
**OpenAIâ€™s** GPT generates contextually relevant responses based on retrieved data.

Workflow: User queries are processed by LangChain, which retrieves relevant data from PostgreSQL and ChromaDB. OpenAIâ€™s model then generates responses informed by this data. This setup allows for real-time, adaptive systems that improve as more data is added.

This architecture is ideal for applications like customer support, personalized content generation, and knowledge management, providing a scalable, context-aware solution for data-driven content generation.


### ğŸš€ Tech Stack Overview:

| ğŸ§© Layer             | âš™ï¸ Technology                 | ğŸ“ Description |
|----------------------|------------------------------|----------------|
| ğŸ’» Language           | `Python`                     | Base language for the app |
| ğŸ”— Framework          | `FastAPI`                    | Lightweight web API framework |
| ğŸ§  LLM & Orchestration | `LangChain`, `LangGraph`     | Manages prompt flows and toolchains |
| ğŸ§® Embeddings         | `OpenAIEmbeddings`           | Turns text into numerical vectors |
| ğŸ“¦ Vector Store       | `ChromaDB`                   | Used to store and search document chunks |
| ğŸ“‚ Document Loader    | `unstructured`, `markdown`   | Handles parsing `.md` files |
| ğŸ§  Chat Memory        | `LangGraph SQLite Checkpoint`| Maintains session history by user |
| ğŸ¤– Model              | `gpt-4o-mini`                | OpenAI ChatGPT model |
| ğŸ“œ Logging            | `aiologger`, `logger.py`     | Custom async logging system |
| ğŸ˜ Database           | `PostgreSQL` (via Docker)    | Stores relational data like metadata or session info |
| ğŸ³ Containerization   | `Docker`, `Docker Compose`   | Manages isolated app environments and service orchestration |


## ğŸ—‚ï¸ Project Structure

```bash
.
â”œâ”€â”€ .dockerignore                  # ğŸ”¥ docker ignore file
â”œâ”€â”€ .gitignore                  # ğŸ”¥ docker ignore file
â”œâ”€â”€ docker-compose.yml                  # ğŸ”¥ docker compose file
â”œâ”€â”€ how_to_run_docker.md                  # ğŸ”¥ docker documentation file
â”œâ”€â”€ Dockerfile                  # ğŸ”¥ docker file
â”œâ”€â”€ api_server.py                  # ğŸ”¥ FastAPI app entry
â”œâ”€â”€ start.py                  # ğŸ”¥ Entry point Due to windows machine add this one
â”œâ”€â”€ api_tools.py             # ğŸ§  Core AI logic
â”œâ”€â”€ logger.py                # ğŸªµ Logging setup
â”œâ”€â”€ docs/                    # ğŸ“„ Source markdown files
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ chromadb/            # ğŸ“¦ ChromaDB persistent storage
â”œâ”€â”€ logs/                    # ğŸ“œ Log files
â”œâ”€â”€ .env                     # ğŸ” Env variables
â””â”€â”€ requirements.txt         # ğŸ“¦ All required dependencies
```


## ğŸ”§ Environment Configuration (`.env`)

```ini
OPENAI_API_KEY=your_openai_api_key
DB_PATH=db/chromadb/db_name
DB_COLLECTION_NAME=db_collection_name
DOCUMENT_PATH=docs
CHUNK_SIZE=500
CHUNK_OVERLAP=100
CHATSESSION_DATABASE_PATH=postgresql://postgres:postgres@postgres/rag-demo
```


## ğŸ“¦ Dependencies (`requirements.txt`)

```txt
Flask
openai
chromadb
langchain
langchain-core
langchain-text-splitters
langchain_chroma
langchain-community
aiologger
aiofiles
langgraph
langgraph.checkpoint.sqlite
unstructured
markdown
langchain-openai
psycopg
psycopg-binary
langgraph.checkpoint.postgres
```

âœ… Add this to `requirements.txt` and run:

```bash
pip install -r requirements.txt
```


## ğŸ“¡ API Reference

### Endpoint: `POST /chat/start`

#### Payload:
```json
{
  "phone_number": "1234567890",
  "question": "Tell me about tourist places in Gujarat."
}
```

#### Response:
```json
{
  "phone_number": "1234567890",
  "message": "Here are some popular places to visit in Gujarat..."
}
```

ğŸ§  Uses vector search to find relevant document snippets and generate a coherent answer using GPT.


## ğŸ§  AI Flow Overview

```
graph TD
    A[User Input (question + phone number)] --> B[Vector Search with ChromaDB]
    B --> C[Retrieve Top-K Matching Chunks]
    C --> D[Format Prompt Template]
    D --> E[Send to OpenAI API]
    E --> F[Generate AI Response]
    F --> G[Return API Response + Store Chat in SQLite]
```


## ğŸ§  Core Components

### 1. `logger.py` ğŸ“œ
Creates a rotating file logger and logs to console and file.

### 2. `api_tools.py` ğŸ§©
Contains the following:
- **VectorStore class**: loads markdown docs, splits them, creates vector embeddings, and stores in ChromaDB.
- **get_vector_store**: lazy loads vector store singleton.
- **Prompt**: a formatted LangChain prompt for OpenAI.
- **create_agent + create_workflow_graph**: builds conversational graph logic using LangGraph.
- **invoke_model**: stores/retrieves session state from SQLite and invokes AI response.
- **chat_start_api**: the actual API logic to handle chat input.

### 3. `api_server.py` ğŸš€
Starts FastAPI server and handles incoming chat POST requests.


## ğŸš€ How It Works

### ğŸ§¬ Initialization
- `lifespan()` runs on app startup and:
  - Initializes the AI graph with memory
  - Loads the vector DB and documents

### ğŸ“¤ Chat Flow
1. User hits `/chat/start` with `phone_number` and `question`.
2. Vector search pulls top 2 similar document chunks.
3. A prompt is created with those results.
4. OpenAI generates a response formatted professionally.
5. Result is returned and stored in SQLite memory.


## ğŸ’¬ Prompt Design

```text
You are a helpful assistant for a tourism chatbot.
Use ONLY the context provided below to answer the user's question.
If not present, refer them to contact info from vector DB.

---
Context:
{context}
---

Question:
{question}

Answer:
Format your response clearly and professionally.
```


## âœ… Supported File Types

ğŸ“ All document files in the `docs/` folder must be:
- Markdown format (`.md` only)

> You can extend `VectorStore.legal_file_extensions` to support `.pdf`, `.docx`, etc.


## ğŸš€ Running the App

1. Create a `.env` file with your values.
2. Add markdown files in the `docs/` folder.
3. Run the app:
   ```bash
   python main.py
   ```

ğŸ§ª Test via Postman or any HTTP client:
```http
POST http://127.0.0.1:8000/chat/start
```


## ğŸ” Features

âœ… Markdown file ingestion  
âœ… Vector similarity search  
âœ… Prompted GPT-based response  
âœ… Phone number-based chat memory  
âœ… Logging to both file and console  
âœ… Handles doc chunking (500 tokens w/ 100 overlap)


## ğŸ“Œ Dev Tips

- To add support for `.docx` or `.pdf`, extend `VectorStore.legal_file_extensions` and add the loader.
- Vector DB is only populated if empty â€“ smart init!
- Chat sessions are tracked using `phone_number` ğŸ§¾


## Want to Learn More? ğŸ¤“

If you're passionate about **AI/ML**, **Node.js**, or **DevOps**, Iâ€™d love to connect and collaborate! Whether you're working on a project, need help with architecture, or just want to brainstorm cool tech stuff â€” Iâ€™m here to help! ğŸ’¡âœ¨

ğŸ‘‰ **Follow me on Medium** for tutorials, guides, and deep dives into real-world tech problems. [Medium](https://prashant1879.medium.com/) ğŸ“š  
ğŸ‘‰ **Need help with an AI/ML project?** Letâ€™s talk! Reach out to me directly on [LinkedIn](https://www.linkedin.com/in/prashantsuthar1/). ğŸ¤–ğŸ’¬

Stay curious, stay awesome, and keep coding! ğŸ‘¨â€ğŸ’»ğŸ‘©â€ğŸ’»ğŸš€
